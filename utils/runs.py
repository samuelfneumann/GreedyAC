import numpy as np
from copy import deepcopy

TRAIN = "train"
EVAL = "eval"


def episodes_to(in_data, i, type_=TRAIN):
    """
    Restricts the number of `type_` episodes to be from episode 0 to the
    episode right before episode i.
    The input data dictionary is not changed. If `type_` is 'train', then the
    training returns are restricted to be only from episodes 0 to i and the
    'eval' episodes are restricted to reflect this. If `type_` is 'eval", then
    the evaluation returns are restricted to be only from episode 0 to i and
    the 'train' returns are restricted to reflect this.

    By 'restricted to reflect this', we mean that the returns are
    restricted so that the final return is at the same timestep (or
    nearest timestep, rounding up to episode completion) as the
    final timestep of episode i for the data of type `type_`.


    Parameters
    ----------
    in_data : dict
        The data dictionary
    i : int
        The episode to restrict values to
    type_ : str
        The type of data to restrict to be from episode 0 to i. One
        of 'train', 'eval'.

    Returns
    -------
    dict
        The modified data dictionary
    """
    data = deepcopy(in_data)

    if type_ not in (TRAIN, EVAL):
        raise ValueError("type_ must be one of 'train',  'eval'")

    key = type_
    other = "eval" if key == "train" else "train"

    for hyper in data["experiment_data"]:
        for j in range(len(data["experiment_data"][hyper]["runs"])):
            run_data = data["experiment_data"][hyper]["runs"][j]

            if i > len(run_data[f"{key}_episode_rewards"]):
                last = len(run_data[f"{key}_episode_rewards"])
                raise IndexError(f"no such episode i={i}, largest episode " +
                                 f"index is {last}")

            # Adjust training data
            run_data[f"{key}_episode_rewards"] = run_data[
                f"{key}_episode_rewards"][:i]

            run_data[f"{key}_episode_steps"] = run_data[
                f"{key}_episode_steps"][:i]

            # Figure out which timestep episode i happened on
            last_step = np.cumsum(run_data[f"{key}_episode_steps"])[-1]

            # Figure out which episodes to keep of the "other" type (if type_
            # is 'train' then other is 'eval' and vice versa)
            to_discard = np.cumsum(run_data[f"{other}_episode_steps"]) \
                > last_step

            if len(to_discard):
                last_other_step = np.argmax(to_discard)

                # Adjust "other" data
                run_data[f"{other}_episode_reward"] = run_data[
                    f"{other}_episode_reward"][:last_other_step]

                run_data[f"{other}_episode_steps"] = run_data[
                    f"{other}_episode_steps"][:last_other_step]
            else:
                # Adjust "other" data
                run_data[f"{other}_episode_reward"] = []

                run_data[f"{other}_episode_steps"] = []

    return data


def expand_episodes(data, ind, type_='train'):
    """
    For each run, repeat each episode's performance measure by how many
    timesteps that episode took to finish. This results in episodic experiments
    having the same number of data readings per run, so that performances can
    be averaged over runs and an be easily plotted.

    This function will modify a single run's data such that if you plotted only
    that run's data, then it would appear as a step plot. For example, if we
    had the following episode performances:

        [100, 110]

    with the following number of timesteps for each episode:

        [2, 3]

    Then this function will modify the data so that it looks like:

        [100, 100, 110, 110, 110]

    Parameters
    ----------
    data : dict
        The data dictionary generated by the experiment
    ind : int
        The hyperparameter index to adjust
    type_ : str
        Which data type to adjust, one of 'train', 'eval'
    """
    data = deepcopy(data)
    runs = data["experiment_data"][ind]["runs"]
    episodes = []
    if type_ == "train":
        for i in range(len(runs)):
            run_return = []
            for j in range(len(runs[i]["train_episode_rewards"])):
                run_return.extend([runs[i]["train_episode_rewards"][j] for _ in
                                  range(runs[i]["train_episode_steps"][j])])
            data["experiment_data"][ind]["runs"][i][
                "train_episode_rewards"] = run_return

    elif type_ == "eval":
        for i in range(len(runs)):
            run_return = []
            for j in range(len(runs[i]["eval_episode_rewards"])):
                run_return.extend([runs[i]["eval_episode_rewards"][j] for _ in
                                   range(runs[i]["eval_episode_steps"][j])])
            data["experiment_data"][ind]["runs"][i][
                "eval_episode_rewards"] = run_return

    else:
        raise ValueError(f"unknown type {type_}")
    return data


def reduce_episodes(data, ind, type_):
    """
    Reduce the number of episodes in an episodic setting

    Given a data dictionary, this function will reduce the number of episodes
    seen on each run to the minimum among all runs for that hyperparameter
    settings index. This is needed to plot curves by episodic return.

    Parameters
    ----------
    data : dict
        The Python data dictionary generated from running main.py
    ind : int
        The hyperparameter settings index to reduce the episodes of
    type_ : str
        Whether to reduce the training or evaluation returns, one of 'train',
        'eval'
    """
    data = deepcopy(data)
    runs = data["experiment_data"][ind]["runs"]
    episodes = []
    if type_ == "train":
        for run in data["experiment_data"][ind]["runs"]:
            episodes.append(len(run["train_episode_rewards"]))

        min_ = np.min(episodes)
        for i in range(len(runs)):
            runs[i]["train_episode_rewards"] = \
                runs[i]["train_episode_rewards"][:min_]

    elif type_ == "eval":
        for run in data["experiment_data"][ind]["runs"]:
            episodes.append(run["eval_episode_rewards"].shape[0])

        min_ = np.min(episodes)

        for i in range(len(runs)):
            runs[i]["eval_episode_rewards"] = \
                runs[i]["eval_episode_rewards"][:min_, :]

    return data


def before(data, i):
    """
    Only keep the runs up until i
    """
    for hyper in data["experiment_data"]:
        data["experiment_data"][hyper]["runs"] = \
            data["experiment_data"][hyper]["runs"][:i]

    return data


def after(data, i):
    """
    Only keep runs after i
    """
    for hyper in data["experiment_data"]:
        data["experiment_data"][hyper]["runs"] = \
            data["experiment_data"][hyper]["runs"][i:]

    return data


def combine(data1, data2):
    """
    Adds the runs from `data2` to `data1` if they are not already in `data1`
    while ignoring hyper settings in `data2` that do not exist in `data1`. This
    function assumes that the hypers indices are consistent between `data1` and
    `data2`, i.e. hyper index `i` refers to the same hyperparameter
    configuration in both data files.

    `data1` is mutated.

    Parameters
    ----------
    data1 : dict[any]any
        The destination data dictionary to add runs to
    data2 : dict[any]any
        The source data dictionary to get runs from
    """
    for hyper in data1["experiment_data"]:
        if hyper not in data2["experiment_data"]:
            continue

        used_random_seeds = []
        for run1 in data1["experiment_data"][hyper]["runs"]:
            used_random_seeds.append(run1["random_seed"])

        for run2 in data2["experiment_data"][hyper]["runs"]:
            if run2["random_seed"] not in used_random_seeds:
                data1["experiment_data"][hyper]["runs"].append(run2)

    return data1


def to(data, i):
    return before(data, i)
